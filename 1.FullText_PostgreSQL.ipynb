{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Loading Text Search in PostgreSQL\n",
    "\n",
    "## OUTLINE\n",
    " 1. [PostgreSQL Text storage](#PG_text)\n",
    " 1. [Task at hand](#task)\n",
    " 1. [Buiding our Text Document Retrieval DB](#build_it)\n",
    " 1. [Loading Data](#load_it)\n",
    " 1. [Executing Queries, Google-lite...very very lite](#search_me) \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<a id='PG_text' ></a>\n",
    "\n",
    "## PostgreSQL Text Storage\n",
    "\n",
    "PostgreSQL is the most powerful and flexible open-source relational database management system (RDBMS) available.\n",
    "As you may know, it is actually an Object-Relational DBMS (ORDBMS).\n",
    "Beyond these capabilities, PostgreSQL supports extensibility including No-SQL extensions, JSON extensions, and Spatial / Geospatial extensions.\n",
    "There are many extensions available, and this notebook focuses on an Information Retrieval (IR) based extension, _full text search_.\n",
    "\n",
    "### PostgreSQL Textual Field (column) Types\n",
    "\n",
    "| Name                             | Description                |  \n",
    "| -------------------------------- | -------------------------- |  \n",
    "| character varying(n), varchar(n) | variable-length with limit |  \n",
    "| character(n), char(n)            | fixed-length, blank padded |  \n",
    "| text                             | variable unlimited length  |  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the manual\n",
    "\n",
    "In addition, PostgreSQL provides the `text` type, which stores strings of any length. \n",
    "Although the type `text` is not in the SQL standard, several other SQL database management systems have it as well.\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "In any case, the longest possible character string that can be stored is about 1 GB. \n",
    "\n",
    "...\n",
    "\n",
    "**If you desire to store long strings with no specific upper limit, use text or character varying without a length specifier, rather than making up an arbitrary length limit.**\n",
    "\n",
    "---\n",
    "So, `text` fields have no size limit, per se.\n",
    "In reality, the underlying computer system may impose some limits.\n",
    "\n",
    "In the details of things, `text` and other large objects are optimized for storage by being compressed into backup tables to accelerate relational operations on other columns.\n",
    " * When you have spare time, [read about PostgreSQL TOASTing](https://www.postgresql.org/docs/9.5/static/storage-toast.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task' /> </a>\n",
    "\n",
    "## Task at Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we are going to walk through the process of creating full text search capability within PostgreSQL for integration into other analytical processes.\n",
    "\n",
    "Back in 2013, I did a quick Google search for _complete multi chapter book text files_ ... or something similar.\n",
    "\n",
    "Building systems to access unstructured data has been a long-standing challange in computer and information science.\n",
    "It was a fun exercise for my _High-Performance Computing_ CS students to build distributed systems with low-level C/C++ and MPI techniques.\n",
    "There are a lot of fun algorithmic and engineering complexities they had to deal with, as well as designing and constructing proper data structures, managing communication among nodes and such.\n",
    "\n",
    "Luckily for this course, we have two stellar tools: **PostgreSQL** and **Python**.\n",
    "The process will take very little time and the usability of the full text search is multiplied by the degree of heterogeneous data that can be integrated with the full text search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database of Unstructured Text Files \n",
    "\n",
    "I was hoping to find  [_\"The Art of Computer Programming\"_](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming).  \n",
    "Intead found this somewhat influential book as a collection of data files; it would have to work.\n",
    "It is 4.6 megabytes of text and 31 thousand lines, sounds fun! These files are physically located here: `/dsa/data/all_datasets/book/` and can be browsed from the jupyter home page in the `datasets/book` folder. \n",
    "\n",
    "```BASH\n",
    "$ ls /dsa/data/all_datasets/book/*\n",
    "book/1chron.txt    book/acts.txt      book/isaiah.txt    book/nahum.txt\n",
    "book/1corinth.txt  book/amos.txt      book/james.txt     book/nehemiah.txt\n",
    "book/1john.txt     book/colossia.txt  book/jeremiah.txt  book/numbers.txt\n",
    "book/1kings.txt    book/daniel.txt    book/job.txt       book/obadiah.txt\n",
    "book/1peter.txt    book/deut.txt      book/joel.txt      book/philemon.txt\n",
    "book/1samuel.txt   book/eccl.txt      book/john.txt      book/philipp.txt\n",
    "book/1thess.txt    book/ephesian.txt  book/jonah.txt     book/proverbs.txt\n",
    "book/1timothy.txt  book/esther.txt    book/joshua.txt    book/psalms.txt\n",
    "book/2chron.txt    book/exodus.txt    book/jude.txt      book/rev.txt\n",
    "book/2corinth.txt  book/ezekiel.txt   book/judges.txt    book/romans.txt\n",
    "book/2john.txt     book/ezra.txt      book/lament.txt    book/ruth.txt\n",
    "book/2kings.txt    book/galatian.txt  book/levit.txt     book/song.txt\n",
    "book/2peter.txt    book/genesis.txt   book/luke.txt      book/titus.txt\n",
    "book/2samuel.txt   book/habakkuk.txt  book/malachi.txt   book/zech.txt\n",
    "book/2thess.txt    book/haggai.txt    book/mark.txt      book/zeph.txt\n",
    "book/2timothy.txt  book/hebrews.txt   book/matthew.txt\n",
    "book/3john.txt     book/hosea.txt     book/micah.txt\n",
    "\n",
    "$ du -skh /dsa/data/all_datasets/book\n",
    "4.6M\t/dsa/data/all_datasets/book\n",
    "$ wc -l book/*  | tail -n1\n",
    "  31258 total\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build_it' /> </a>\n",
    "\n",
    "## Building a Text Retrieval Database\n",
    "\n",
    "<span style=\"color:red\">\n",
    "**You will need create and load the database similarly to how you interacted with PostgreSQL in the Database and Analytics course.**\n",
    "</span>\n",
    "\n",
    "Remember a few key things:\n",
    " 1. You will use your pawprint as your user name, and the password you will type in is your normal MU password.\n",
    " 1. The database is: `dsa_student`\n",
    " 1. The database host is: `pgsql.dsa.lan`\n",
    " 1. The schema name is the same as your pawprint.\n",
    "\n",
    "#### All the commands shown and annotated are available [here](../resources/PG_Build_Bible_Search.sql).\n",
    "\n",
    "You will need to open the terminal, then connect to the database to build your schema tables.\n",
    "\n",
    "<span style=\"background-color:yellow\">For the commands below, replace the schema name `sebcq5` with your own pawprint.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in terminal:\n",
    "#    psql -h pgsql.dsa.lan dsa_student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Namespace and data repository within database.\n",
    "\n",
    "```SQL\n",
    "\n",
    "-------------------------\n",
    "-- Basic Table \n",
    "-------------------------\n",
    "\n",
    "CREATE TABLE dlfy6.BookSearch(\n",
    "\tid SERIAL NOT NULL,\n",
    "\tname varchar(250) NOT NULL,\n",
    "\tcontent text NOT NULL\n",
    ");\n",
    "\n",
    "ALTER TABLE dlfy6.BookSearch\n",
    "ADD CONSTRAINT pk_BookSearch PRIMARY KEY (id);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Add a column that implements the vector model, then parse the data into it.\n",
    "\n",
    "```SQL\n",
    "-------------------------\n",
    "-- Separate Ts_Vector column\n",
    "-------------------------\n",
    "-- TS_Vector for GIN INDEX\n",
    "ALTER TABLE dlfy6.BookSearch \n",
    "  ADD COLUMN content_tsv_gin tsvector;\n",
    "  \n",
    "UPDATE dlfy6.BookSearch \n",
    "SET content_tsv_gin = to_tsvector('pg_catalog.english', content);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add another column that implements the vector model, then parse the data into it.\n",
    "\n",
    "```SQL\n",
    "-- TS_Vector for GIST INDEX\n",
    "ALTER TABLE dlfy6.BookSearch \n",
    "  ADD COLUMN content_tsv_gist tsvector;\n",
    "\n",
    "UPDATE dlfy6.BookSearch \n",
    "SET content_tsv_gist = to_tsvector('pg_catalog.english', content);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Set up database triggers to parse all new content loaded into the vector models.\n",
    "\n",
    "```SQL\n",
    "--TRIGGER\n",
    "CREATE TRIGGER tsv_gin_update \n",
    "\tBEFORE INSERT OR UPDATE\n",
    "\tON dlfy6.BookSearch \n",
    "\tFOR EACH ROW \n",
    "\tEXECUTE PROCEDURE \n",
    "\ttsvector_update_trigger(content_tsv_gin,'pg_catalog.english',content);\n",
    "\n",
    "CREATE TRIGGER tsv_gist_update \n",
    "\tBEFORE INSERT OR UPDATE\n",
    "\tON dlfy6.BookSearch \n",
    "\tFOR EACH ROW \n",
    "    EXECUTE PROCEDURE\n",
    "\ttsvector_update_trigger(content_tsv_gist,'pg_catalog.english',content);\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  Add a specialized indexing to the vector models.\n",
    "\n",
    "```SQL\n",
    "-------------------------\n",
    "-- Create Indexes\n",
    "-------------------------\n",
    "\n",
    "-- Index on content (Trigram needed,to use Gin Index)\n",
    "-- CREATE EXTENSION pg_trgm;  -- Done by DB Admin\n",
    "\n",
    "CREATE INDEX BookSearch_content\n",
    "ON dlfy6.BookSearch USING GIN(content gin_trgm_ops);\n",
    "\n",
    "-- GIN INDEX on content_tsv_gin\n",
    "CREATE INDEX BookSearch_content_tsv_gin\n",
    "ON dlfy6.BookSearch USING GIN(content_tsv_gin);\n",
    "\n",
    "-- GIST INDEX on content_tsv_gist\n",
    "CREATE INDEX BookSearch_content_tsv_gist\n",
    "ON dlfy6.BookSearch USING GIST(content_tsv_gist);\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "NOTE: Read briefly about [trigrams](https://en.wikipedia.org/wiki/Trigram), you may see these again with computational linguistics later.\n",
    "\n",
    "Finally, take a look at the resulting table definition:\n",
    "\n",
    "```SQL\n",
    "dsa_student=# \\dt sebcq5.\n",
    "          List of relations\n",
    " Schema |    Name    | Type  | Owner\n",
    "--------+------------+-------+--------\n",
    " sebcq5 | booksearch | table | sebcq5\n",
    "(1 row)\n",
    "\n",
    "dsa_student=# \\d sebcq5.booksearch\n",
    "                                         Table \"sebcq5.booksearch\"\n",
    "      Column      |          Type          | Collation | Nullable |                Default\n",
    "------------------+------------------------+-----------+----------+----------------------------------------\n",
    " id               | integer                |           | not null | nextval('booksearch_id_seq'::regclass)\n",
    " name             | character varying(250) |           | not null |\n",
    " content          | text                   |           | not null |\n",
    " content_tsv_gin  | tsvector               |           |          |\n",
    " content_tsv_gist | tsvector               |           |          |\n",
    "Indexes:\n",
    "    \"pk_booksearch\" PRIMARY KEY, btree (id)\n",
    "    \"booksearch_content\" gin (content gin_trgm_ops)\n",
    "    \"booksearch_content_tsv_gin\" gin (content_tsv_gin)\n",
    "    \"booksearch_content_tsv_gist\" gist (content_tsv_gist)\n",
    "Triggers:\n",
    "    tsv_gin_update BEFORE INSERT OR UPDATE ON booksearch FOR EACH ROW EXECUTE PROCEDURE tsvector_update_trigger('content_tsv_gin','pg_catalog.english', 'content')\n",
    "    tsv_gist_update BEFORE INSERT OR UPDATE ON booksearch FOR EACH ROW EXECUTE PROCEDURE tsvector_update_trigger('content_tsv_gist', 'pg_catalog.english', 'content')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_it' /> </a>\n",
    "\n",
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the data, we will use a python script with follow the basic crawling behavior\n",
    "\n",
    " 1. For each file/folder in the specified starting folder:\n",
    " 1. If it is a folder, recurse into folder and process contents\n",
    " 1. If it is a file, read contents and load into database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "# This collects a masked password from the user\n",
    "mypasswd = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myuserid = \"dlfy6\"\n",
    "dbname = \"dsa_student\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\"host='pgsql.dsa.lan' port='5432' dbname='{}' user='{}' password='{}'\".format(dbname,myuserid,mypasswd))\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")\n",
    "\n",
    "def loadFile(filename):\n",
    "    '''\n",
    "    Read file contents, load into database.\n",
    "    \n",
    "    Returns: The document ID that was created\n",
    "    '''\n",
    "    with open(filename, 'r') as infile:\n",
    "        content=infile.read()\n",
    "        with conn, conn.cursor() as curs:\n",
    "            # Note the schema name usage\n",
    "            SQL = \"INSERT INTO {}.booksearch(name,content)VALUES (%s,%s) RETURNING id;\".format(myuserid)        \n",
    "            curs.execute(SQL,(filename,content))\n",
    "            document_id = curs.fetchone()[0]\n",
    "    return document_id \n",
    "        \n",
    "\n",
    "def processFolder(folder):\n",
    "    '''\n",
    "    Process a folder for files and subfolders\n",
    "    '''\n",
    "    \n",
    "    print('Processing folder: ',folder)\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        \n",
    "        print(\"root = \", root)\n",
    "        \n",
    "        # Process Files\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                filename = os.path.join(root, file)\n",
    "                print('Processing File:',filename)\n",
    "                document_id = 0\n",
    "                # Comment out this line to watch the next cell walk the tree\n",
    "                document_id = loadFile(filename)\n",
    "                print(\"Document {} created\".format(document_id))\n",
    "                \n",
    "            elif file.endswith(\".html\"):\n",
    "                print(\"HTML Files Not Handled Yet\")\n",
    "\n",
    "        # Recurse into subfolders\n",
    "        for d in dirs:\n",
    "            print(\"recursing into \",d)\n",
    "            processFolder(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder:  /dsa/data/all_datasets/book\n",
      "root =  /dsa/data/all_datasets/book\n",
      "Processing File: /dsa/data/all_datasets/book/song.txt\n",
      "Document 2 created\n",
      "Processing File: /dsa/data/all_datasets/book/1chron.txt\n",
      "Document 3 created\n",
      "Processing File: /dsa/data/all_datasets/book/ruth.txt\n",
      "Document 4 created\n",
      "Processing File: /dsa/data/all_datasets/book/1corinth.txt\n",
      "Document 5 created\n",
      "Processing File: /dsa/data/all_datasets/book/titus.txt\n",
      "Document 6 created\n",
      "Processing File: /dsa/data/all_datasets/book/1john.txt\n",
      "Document 7 created\n",
      "Processing File: /dsa/data/all_datasets/book/1kings.txt\n",
      "Document 8 created\n",
      "Processing File: /dsa/data/all_datasets/book/1peter.txt\n",
      "Document 9 created\n",
      "Processing File: /dsa/data/all_datasets/book/1samuel.txt\n",
      "Document 10 created\n",
      "Processing File: /dsa/data/all_datasets/book/1thess.txt\n",
      "Document 11 created\n",
      "Processing File: /dsa/data/all_datasets/book/1timothy.txt\n",
      "Document 12 created\n",
      "Processing File: /dsa/data/all_datasets/book/2chron.txt\n",
      "Document 13 created\n",
      "Processing File: /dsa/data/all_datasets/book/2corinth.txt\n",
      "Document 14 created\n",
      "Processing File: /dsa/data/all_datasets/book/2john.txt\n",
      "Document 15 created\n",
      "Processing File: /dsa/data/all_datasets/book/2kings.txt\n",
      "Document 16 created\n",
      "Processing File: /dsa/data/all_datasets/book/2peter.txt\n",
      "Document 17 created\n",
      "Processing File: /dsa/data/all_datasets/book/2samuel.txt\n",
      "Document 18 created\n",
      "Processing File: /dsa/data/all_datasets/book/2thess.txt\n",
      "Document 19 created\n",
      "Processing File: /dsa/data/all_datasets/book/2timothy.txt\n",
      "Document 20 created\n",
      "Processing File: /dsa/data/all_datasets/book/3john.txt\n",
      "Document 21 created\n",
      "Processing File: /dsa/data/all_datasets/book/acts.txt\n",
      "Document 22 created\n",
      "Processing File: /dsa/data/all_datasets/book/amos.txt\n",
      "Document 23 created\n",
      "Processing File: /dsa/data/all_datasets/book/colossia.txt\n",
      "Document 24 created\n",
      "Processing File: /dsa/data/all_datasets/book/daniel.txt\n",
      "Document 25 created\n",
      "Processing File: /dsa/data/all_datasets/book/deut.txt\n",
      "Document 26 created\n",
      "Processing File: /dsa/data/all_datasets/book/eccl.txt\n",
      "Document 27 created\n",
      "Processing File: /dsa/data/all_datasets/book/ephesian.txt\n",
      "Document 28 created\n",
      "Processing File: /dsa/data/all_datasets/book/esther.txt\n",
      "Document 29 created\n",
      "Processing File: /dsa/data/all_datasets/book/exodus.txt\n",
      "Document 30 created\n",
      "Processing File: /dsa/data/all_datasets/book/ezekiel.txt\n",
      "Document 31 created\n",
      "Processing File: /dsa/data/all_datasets/book/ezra.txt\n",
      "Document 32 created\n",
      "Processing File: /dsa/data/all_datasets/book/galatian.txt\n",
      "Document 33 created\n",
      "Processing File: /dsa/data/all_datasets/book/genesis.txt\n",
      "Document 34 created\n",
      "Processing File: /dsa/data/all_datasets/book/habakkuk.txt\n",
      "Document 35 created\n",
      "Processing File: /dsa/data/all_datasets/book/haggai.txt\n",
      "Document 36 created\n",
      "Processing File: /dsa/data/all_datasets/book/hebrews.txt\n",
      "Document 37 created\n",
      "Processing File: /dsa/data/all_datasets/book/hosea.txt\n",
      "Document 38 created\n",
      "Processing File: /dsa/data/all_datasets/book/isaiah.txt\n",
      "Document 39 created\n",
      "Processing File: /dsa/data/all_datasets/book/james.txt\n",
      "Document 40 created\n",
      "Processing File: /dsa/data/all_datasets/book/jeremiah.txt\n",
      "Document 41 created\n",
      "Processing File: /dsa/data/all_datasets/book/job.txt\n",
      "Document 42 created\n",
      "Processing File: /dsa/data/all_datasets/book/joel.txt\n",
      "Document 43 created\n",
      "Processing File: /dsa/data/all_datasets/book/john.txt\n",
      "Document 44 created\n",
      "Processing File: /dsa/data/all_datasets/book/jonah.txt\n",
      "Document 45 created\n",
      "Processing File: /dsa/data/all_datasets/book/joshua.txt\n",
      "Document 46 created\n",
      "Processing File: /dsa/data/all_datasets/book/jude.txt\n",
      "Document 47 created\n",
      "Processing File: /dsa/data/all_datasets/book/judges.txt\n",
      "Document 48 created\n",
      "Processing File: /dsa/data/all_datasets/book/lament.txt\n",
      "Document 49 created\n",
      "Processing File: /dsa/data/all_datasets/book/levit.txt\n",
      "Document 50 created\n",
      "Processing File: /dsa/data/all_datasets/book/luke.txt\n",
      "Document 51 created\n",
      "Processing File: /dsa/data/all_datasets/book/malachi.txt\n",
      "Document 52 created\n",
      "Processing File: /dsa/data/all_datasets/book/mark.txt\n",
      "Document 53 created\n",
      "Processing File: /dsa/data/all_datasets/book/matthew.txt\n",
      "Document 54 created\n",
      "Processing File: /dsa/data/all_datasets/book/micah.txt\n",
      "Document 55 created\n",
      "Processing File: /dsa/data/all_datasets/book/nahum.txt\n",
      "Document 56 created\n",
      "Processing File: /dsa/data/all_datasets/book/nehemiah.txt\n",
      "Document 57 created\n",
      "Processing File: /dsa/data/all_datasets/book/numbers.txt\n",
      "Document 58 created\n",
      "Processing File: /dsa/data/all_datasets/book/obadiah.txt\n",
      "Document 59 created\n",
      "Processing File: /dsa/data/all_datasets/book/philemon.txt\n",
      "Document 60 created\n",
      "Processing File: /dsa/data/all_datasets/book/philipp.txt\n",
      "Document 61 created\n",
      "Processing File: /dsa/data/all_datasets/book/proverbs.txt\n",
      "Document 62 created\n",
      "Processing File: /dsa/data/all_datasets/book/psalms.txt\n",
      "Document 63 created\n",
      "Processing File: /dsa/data/all_datasets/book/rev.txt\n",
      "Document 64 created\n",
      "Processing File: /dsa/data/all_datasets/book/romans.txt\n",
      "Document 65 created\n",
      "Processing File: /dsa/data/all_datasets/book/zech.txt\n",
      "Document 66 created\n",
      "Processing File: /dsa/data/all_datasets/book/zeph.txt\n",
      "Document 67 created\n",
      "recursing into  one_level_down\n",
      "Processing folder:  one_level_down\n",
      "root =  /dsa/data/all_datasets/book/one_level_down\n",
      "recursing into  two_levels_down\n",
      "Processing folder:  two_levels_down\n",
      "root =  /dsa/data/all_datasets/book/one_level_down/two_levels_down\n",
      "Processing File: /dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt\n",
      "Document 68 created\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# Launch the Parsing\n",
    "###########################\n",
    "\n",
    "processFolder('/dsa/data/all_datasets/book');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The output for  the above code should look similar to [here](../resources/PG_FTS_load_output.txt).\n",
    "\n",
    "### Check the Results\n",
    "\n",
    "```SQL\n",
    "dsa_student=# select count(*),sum(length(content)) from sebcq5.booksearch;\n",
    " count |   sum\n",
    "-------+---------\n",
    "    67 | 4346482\n",
    "(1 row)\n",
    "```\n",
    "\n",
    "#### Looking at the last file that I added a few levels deep to test!\n",
    "\n",
    "```SQL\n",
    "dsa_student=# \\x \n",
    "Expanded display is on.\n",
    "dsa_student=# select * from sebcq5.booksearch where id = 67;\n",
    "-[ RECORD 1 ]----+--------------------------------------------------------------------\n",
    "id               | 67\n",
    "name             | /dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt\n",
    "content          | This is just a test file                                           +\n",
    "                 |\n",
    "content_tsv_gin  | 'file':6 'test':5\n",
    "content_tsv_gist | 'file':6 'test':5\n",
    "```\n",
    "\n",
    "Notice that we have built a document vector that has removed common and stop words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='search_me' /> </a>\n",
    "\n",
    "## Executing Queries\n",
    "### Google-lite...very very lite\n",
    "\n",
    "Recall, from the video lecture, the database is now a collection of vectors. \n",
    "\n",
    "Now, to query the database we must convert our queries into vectors for matching.\n",
    "\n",
    "For full documentation, you will want to consult the PostgreSQL documentation.\n",
    "  * https://www.postgresql.org/docs/current/static/textsearch.html\n",
    "  * https://www.postgresql.org/docs/current/static/textsearch-controls.html\n",
    "  * https://www.postgresql.org/docs/current/static/textsearch-features.html\n",
    "\n",
    "Below we show a few examples, which you can play with and adjust as you see fit.\n",
    "\n",
    "<span style=\"color:red\">**The following cells are for you to execute.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic connection with the DSA Readonly User\n",
    "\n",
    "To prepare your DB to be read, you will need to grant the `dsa_ro_user` \n",
    "schema access and select privileges on your table.\n",
    "\n",
    "```SQL\n",
    "GRANT USAGE ON SCHEMA dlfy6 TO dsa_ro_user;\n",
    "GRANT SELECT ON dlfy6.BookSearch TO dsa_ro_user;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dsa_ro_user@dsa_student'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql postgres://dsa_ro_user:readonly@pgsql.dsa.lan/dsa_student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A couple of query examples\n",
    "\n",
    "NOTE:\n",
    "```\n",
    "%%sql\n",
    "```\n",
    "... allows multi-line SQL statements\n",
    "\n",
    "NOTE:\n",
    "Query terms can be joined with boolean operators, \n",
    "  * `|` is \"or\" \n",
    "  * `&` is \"and\"\n",
    "  \n",
    "  \n",
    "**<span style=\"background:yellow\">Change the schema to your schema name in each query below!</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dsa_ro_user:***@pgsql.dsa.lan/dsa_student\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>name</th>\n",
       "        <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>67</td>\n",
       "        <td>/dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt</td>\n",
       "        <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9</td>\n",
       "        <td>/dsa/data/all_datasets/book/1samuel.txt</td>\n",
       "        <td>0.1</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(67, '/dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt', 0.2),\n",
       " (9, '/dsa/data/all_datasets/book/1samuel.txt', 0.1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM dlfy6.booksearch, to_tsquery('test | file') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dsa_ro_user:***@pgsql.dsa.lan/dsa_student\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>name</th>\n",
       "        <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>67</td>\n",
       "        <td>/dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt</td>\n",
       "        <td>0.1</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(67, '/dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt', 0.1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM dlfy6.booksearch, to_tsquery('test & file') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dsa_ro_user:***@pgsql.dsa.lan/dsa_student\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>name</th>\n",
       "        <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6</td>\n",
       "        <td>/dsa/data/all_datasets/book/1john.txt</td>\n",
       "        <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>43</td>\n",
       "        <td>/dsa/data/all_datasets/book/john.txt</td>\n",
       "        <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>/dsa/data/all_datasets/book/song.txt</td>\n",
       "        <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>61</td>\n",
       "        <td>/dsa/data/all_datasets/book/proverbs.txt</td>\n",
       "        <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>27</td>\n",
       "        <td>/dsa/data/all_datasets/book/ephesian.txt</td>\n",
       "        <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>25</td>\n",
       "        <td>/dsa/data/all_datasets/book/deut.txt</td>\n",
       "        <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>64</td>\n",
       "        <td>/dsa/data/all_datasets/book/romans.txt</td>\n",
       "        <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>50</td>\n",
       "        <td>/dsa/data/all_datasets/book/luke.txt</td>\n",
       "        <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>13</td>\n",
       "        <td>/dsa/data/all_datasets/book/2corinth.txt</td>\n",
       "        <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>37</td>\n",
       "        <td>/dsa/data/all_datasets/book/hosea.txt</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(6, '/dsa/data/all_datasets/book/1john.txt', 3.7),\n",
       " (43, '/dsa/data/all_datasets/book/john.txt', 3.4),\n",
       " (1, '/dsa/data/all_datasets/book/song.txt', 2.8),\n",
       " (61, '/dsa/data/all_datasets/book/proverbs.txt', 1.9),\n",
       " (27, '/dsa/data/all_datasets/book/ephesian.txt', 1.7),\n",
       " (25, '/dsa/data/all_datasets/book/deut.txt', 1.5),\n",
       " (64, '/dsa/data/all_datasets/book/romans.txt', 1.4),\n",
       " (50, '/dsa/data/all_datasets/book/luke.txt', 1.2),\n",
       " (13, '/dsa/data/all_datasets/book/2corinth.txt', 1.2),\n",
       " (37, '/dsa/data/all_datasets/book/hosea.txt', 1.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM dlfy6.booksearch, to_tsquery('love') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dsa_ro_user:***@pgsql.dsa.lan/dsa_student\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>name</th>\n",
       "        <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>67</td>\n",
       "        <td>/dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt</td>\n",
       "        <td>0.1</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(67, '/dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt', 0.1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM dlfy6.booksearch, plainto_tsquery('test file') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dsa_ro_user:***@pgsql.dsa.lan/dsa_student\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>name</th>\n",
       "        <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6</td>\n",
       "        <td>/dsa/data/all_datasets/book/1john.txt</td>\n",
       "        <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>43</td>\n",
       "        <td>/dsa/data/all_datasets/book/john.txt</td>\n",
       "        <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>/dsa/data/all_datasets/book/song.txt</td>\n",
       "        <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>61</td>\n",
       "        <td>/dsa/data/all_datasets/book/proverbs.txt</td>\n",
       "        <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>27</td>\n",
       "        <td>/dsa/data/all_datasets/book/ephesian.txt</td>\n",
       "        <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>25</td>\n",
       "        <td>/dsa/data/all_datasets/book/deut.txt</td>\n",
       "        <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>64</td>\n",
       "        <td>/dsa/data/all_datasets/book/romans.txt</td>\n",
       "        <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>50</td>\n",
       "        <td>/dsa/data/all_datasets/book/luke.txt</td>\n",
       "        <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>13</td>\n",
       "        <td>/dsa/data/all_datasets/book/2corinth.txt</td>\n",
       "        <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>37</td>\n",
       "        <td>/dsa/data/all_datasets/book/hosea.txt</td>\n",
       "        <td>1.0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(6, '/dsa/data/all_datasets/book/1john.txt', 3.7),\n",
       " (43, '/dsa/data/all_datasets/book/john.txt', 3.4),\n",
       " (1, '/dsa/data/all_datasets/book/song.txt', 2.8),\n",
       " (61, '/dsa/data/all_datasets/book/proverbs.txt', 1.9),\n",
       " (27, '/dsa/data/all_datasets/book/ephesian.txt', 1.7),\n",
       " (25, '/dsa/data/all_datasets/book/deut.txt', 1.5),\n",
       " (64, '/dsa/data/all_datasets/book/romans.txt', 1.4),\n",
       " (50, '/dsa/data/all_datasets/book/luke.txt', 1.2),\n",
       " (13, '/dsa/data/all_datasets/book/2corinth.txt', 1.2),\n",
       " (37, '/dsa/data/all_datasets/book/hosea.txt', 1.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM dlfy6.booksearch, plainto_tsquery('love') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Please explore different queries\n",
    "\n",
    "  1. Explore changing the query below.\n",
    "  2. Observer how the ranking score is changed with different queries and different numbers of search terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dsa_ro_user:***@pgsql.dsa.lan/dsa_student\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>name</th>\n",
       "        <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>30</td>\n",
       "        <td>/dsa/data/all_datasets/book/ezekiel.txt</td>\n",
       "        <td>0.100541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>62</td>\n",
       "        <td>/dsa/data/all_datasets/book/psalms.txt</td>\n",
       "        <td>0.100076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>41</td>\n",
       "        <td>/dsa/data/all_datasets/book/job.txt</td>\n",
       "        <td>0.100034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>49</td>\n",
       "        <td>/dsa/data/all_datasets/book/levit.txt</td>\n",
       "        <td>0.10003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>12</td>\n",
       "        <td>/dsa/data/all_datasets/book/2chron.txt</td>\n",
       "        <td>0.100016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>40</td>\n",
       "        <td>/dsa/data/all_datasets/book/jeremiah.txt</td>\n",
       "        <td>0.100012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>38</td>\n",
       "        <td>/dsa/data/all_datasets/book/isaiah.txt</td>\n",
       "        <td>0.00672419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>24</td>\n",
       "        <td>/dsa/data/all_datasets/book/daniel.txt</td>\n",
       "        <td>0.00161759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>65</td>\n",
       "        <td>/dsa/data/all_datasets/book/zech.txt</td>\n",
       "        <td>0.000825212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9</td>\n",
       "        <td>/dsa/data/all_datasets/book/1samuel.txt</td>\n",
       "        <td>0.000300964</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(30, '/dsa/data/all_datasets/book/ezekiel.txt', 0.100541),\n",
       " (62, '/dsa/data/all_datasets/book/psalms.txt', 0.100076),\n",
       " (41, '/dsa/data/all_datasets/book/job.txt', 0.100034),\n",
       " (49, '/dsa/data/all_datasets/book/levit.txt', 0.10003),\n",
       " (12, '/dsa/data/all_datasets/book/2chron.txt', 0.100016),\n",
       " (40, '/dsa/data/all_datasets/book/jeremiah.txt', 0.100012),\n",
       " (38, '/dsa/data/all_datasets/book/isaiah.txt', 0.00672419),\n",
       " (24, '/dsa/data/all_datasets/book/daniel.txt', 0.00161759),\n",
       " (65, '/dsa/data/all_datasets/book/zech.txt', 0.000825212),\n",
       " (9, '/dsa/data/all_datasets/book/1samuel.txt', 0.000300964)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM dlfy6.booksearch, plainto_tsquery('stone pride') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dsa_ro_user:***@pgsql.dsa.lan/dsa_student\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>name</th>\n",
       "        <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>/dsa/data/all_datasets/book/1chron.txt</td>\n",
       "        <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>26</td>\n",
       "        <td>/dsa/data/all_datasets/book/eccl.txt</td>\n",
       "        <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>56</td>\n",
       "        <td>/dsa/data/all_datasets/book/nehemiah.txt</td>\n",
       "        <td>0.1</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2, '/dsa/data/all_datasets/book/1chron.txt', 0.1),\n",
       " (26, '/dsa/data/all_datasets/book/eccl.txt', 0.1),\n",
       " (56, '/dsa/data/all_datasets/book/nehemiah.txt', 0.1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM dlfy6.booksearch, plainto_tsquery('music') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, the `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
